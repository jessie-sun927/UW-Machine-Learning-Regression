{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions and Details:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"data_files/kc_house_data.csv\", dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['constant'] = 1 # add a constant column  \n",
    "    features = ['constant'] + features # combine two lists\n",
    "\n",
    "    feature_matrix = data[features].to_numpy()\n",
    "    output_array = data[output].to_numpy()\n",
    "    \n",
    "    return(feature_matrix, output_array) # returns a 2D array and 1D array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features\n",
    "In the house dataset, features vary wildly in their relative magnitude: `sqft_living` is very large overall compared to `bedrooms`, for instance. As a result, weight for `sqft_living` would be much smaller than weight for `bedrooms`. This is problematic because \"small\" weights are dropped first as `l1_penalty` goes up. \n",
    "\n",
    "To give equal considerations for all features, we need to **normalize features** as discussed in the lectures: **we divide each feature by its 2-norm** so that the transformed feature has norm 1.\n",
    "\n",
    "Let's see how we can do this normalization easily with Numpy: let us first consider a small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 13. 17.]\n",
      "[[0.6        0.38461538 0.47058824]\n",
      " [0.8        0.92307692 0.88235294]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3.,5.,8.],[4.,12.,15.]])\n",
    "# Numpy provides a shorthand for computing 2-norms of each column:\n",
    "norms = np.linalg.norm(X, axis=0) # gives [norm(X[:,0]), norm(X[:,1]), norm(X[:,2])]\n",
    "print (norms)\n",
    "# apply element-wise division:\n",
    "print (X / norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the shorthand we just covered, write a short function called `normalize_features(feature_matrix)`, which normalizes columns of a given feature matrix. The function should return a pair `(normalized_features, norms)`, where the second item contains the norms of original features. As discussed in the lectures, we will use these norms to normalize the test data in the same way as we normalized the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis = 0)\n",
    "    normalized_features = features/norms\n",
    "    return normalized_features, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.6 0.6]\n",
      " [0.8 0.8 0.8]]\n",
      "[ 5. 10. 15.]\n"
     ]
    }
   ],
   "source": [
    "# test the function:\n",
    "features, norms = normalize_features(np.array([[3.,6.,9.],[4.,8.,12.]]))\n",
    "print (features)\n",
    "# should print\n",
    "# [[ 0.6  0.6  0.6]\n",
    "#  [ 0.8  0.8  0.8]]\n",
    "print (norms)\n",
    "# should print\n",
    "# [5.  10.  15.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(j, feature_matrix, output, weights, l1_penalty):\n",
    "    prediction = predict_output(feature_matrix, weights)\n",
    "    feature_j = feature_matrix[:,j]\n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    ro_j = np.dot(feature_j, output - (prediction - weights[j] * feature_j))   # extract feature j\n",
    "\n",
    "    if j == 0: # intercept -- do not regularize\n",
    "        new_weight_j = ro_j \n",
    "    elif ro_j < -l1_penalty/2.:\n",
    "        new_weight_j = ro_j + l1_penalty/2\n",
    "    elif ro_j > l1_penalty/2.:\n",
    "        new_weight_j = ro_j - l1_penalty/2\n",
    "    else:\n",
    "        new_weight_j = 0.\n",
    "    \n",
    "    return new_weight_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4255588466910251\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "import math\n",
    "print (lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],[2./math.sqrt(13),3./math.sqrt(10)]]), \n",
    "                                   np.array([1., 1.]), np.array([1., 4.]), 0.1))\n",
    "# should print 0.425558846691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical Coordinate Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    converged = False # trigger the iteration\n",
    "    weight_change_list = np.empty(len(initial_weights))\n",
    "    weights_list = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        for j in range(len(weights_list)): # iterate over coefficients\n",
    "            old_weight = weights_list[j]\n",
    "            weights_list[j] = lasso_coordinate_descent_step(j, feature_matrix, output, weights_list, l1_penalty)\n",
    "            weight_change = abs(weights_list[j] - old_weight)\n",
    "            weight_change_list[j] = weight_change\n",
    "        max_change = np.max(weight_change_list)\n",
    "        if max_change < tolerance:\n",
    "            converged = True\n",
    "    return weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent_1(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    converged = False # trigger the iteration\n",
    "    weight_change_list = np.empty(len(initial_weights))\n",
    "    weights_list = np.zeros((100,len(initial_weights)))\n",
    "    weights_list[0,:] = initial_weights\n",
    "    iteration = 1\n",
    "    print_frequency = 1\n",
    "    while not converged:\n",
    "        \n",
    "        ### === code section for adjusting frequency of debugging output. ===\n",
    "        if iteration == 10:\n",
    "            print_frequency = 10\n",
    "        if iteration == 100:\n",
    "            print_frequency = 100\n",
    "        if iteration%print_frequency==0:\n",
    "            print('Iteration = ' , str(iteration))\n",
    "        ### === end code section ===\n",
    "        \n",
    "        for j in range(len(weight_change_list)): # iterate over coefficients\n",
    "            old_weight = weights_list[iteration-1][j] # use weights from previous round\n",
    "            weights_list[iteration][j] = lasso_coordinate_descent_step(j, feature_matrix, output, weights_list[iteration-1,:], l1_penalty)\n",
    "            weight_change = abs(weights_list[iteration][j] - old_weight)\n",
    "            weight_change_list[j] = weight_change\n",
    "        max_change = np.max(weight_change_list)\n",
    "        if iteration%print_frequency==0:\n",
    "            print('in this iteration', iteration,':', weights_list[iteration,:], '\\n')\n",
    "        \n",
    "        iteration += 1 \n",
    "        if max_change < tolerance or iteration >= 100:\n",
    "            converged = True\n",
    "    return weights_list, weight_change_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_matrix, output) = get_numpy_data(sales, ['sqft_living', 'bedrooms'], 'price')\n",
    "(normalized_feature_matrix, norms) = normalize_features(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21624997.9595191  63157247.20788956        0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(normalized_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  1\n",
      "in this iteration 1 : [79400304.63764462 82939472.68182784 75966703.4053849 ] \n",
      "\n",
      "Iteration =  2\n",
      "in this iteration 2 : [-69701976.78367452 -51391433.00037618 -68851242.31261744] \n",
      "\n",
      "Iteration =  3\n",
      "in this iteration 3 : [1.92783738e+08 2.11682985e+08 1.91660885e+08] \n",
      "\n",
      "Iteration =  4\n",
      "in this iteration 4 : [-2.99001660e+08 -2.64304035e+08 -2.99657732e+08] \n",
      "\n",
      "Iteration =  5\n",
      "in this iteration 5 : [6.10046173e+08 6.39276004e+08 6.13646515e+08] \n",
      "\n",
      "Iteration =  6\n",
      "in this iteration 6 : [-1.09694367e+09 -1.04427573e+09 -1.10544941e+09] \n",
      "\n",
      "Iteration =  7\n",
      "in this iteration 7 : [2.10032083e+09 2.12972039e+09 2.11897805e+09] \n",
      "\n",
      "Iteration =  8\n",
      "in this iteration 8 : [-3.91149156e+09 -3.82827512e+09 -3.94871448e+09] \n",
      "\n",
      "Iteration =  9\n",
      "in this iteration 9 : [7.38793658e+09 7.38787482e+09 7.45966347e+09] \n",
      "\n",
      "Iteration =  10\n",
      "in this iteration 10 : [-1.38698942e+10 -1.37057980e+10 -1.40084766e+10] \n",
      "\n",
      "Iteration =  20\n",
      "in this iteration 20 : [-7.72736584e+12 -7.67092671e+12 -7.80555629e+12] \n",
      "\n",
      "Iteration =  30\n",
      "in this iteration 30 : [-4.30406745e+15 -4.27267960e+15 -4.34761646e+15] \n",
      "\n",
      "Iteration =  40\n",
      "in this iteration 40 : [-2.39732434e+18 -2.37984165e+18 -2.42158071e+18] \n",
      "\n",
      "Iteration =  50\n",
      "in this iteration 50 : [-1.33528669e+21 -1.32554900e+21 -1.34879726e+21] \n",
      "\n",
      "Iteration =  60\n",
      "in this iteration 60 : [-7.43741893e+23 -7.38318095e+23 -7.51267149e+23] \n",
      "\n",
      "Iteration =  70\n",
      "in this iteration 70 : [-4.14257109e+26 -4.11236105e+26 -4.18448605e+26] \n",
      "\n",
      "Iteration =  80\n",
      "in this iteration 80 : [-2.30737241e+29 -2.29054571e+29 -2.33071864e+29] \n",
      "\n",
      "Iteration =  90\n",
      "in this iteration 90 : [-1.28518433e+32 -1.27581202e+32 -1.29818795e+32] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.82525340e+34, 5.78277227e+34, 5.88419391e+34])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights,list = lasso_cyclical_coordinate_descent_1(normalized_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1630492476715386.5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute RSS on normalized dataset\n",
    "predictions = predict_output(normalized_feature_matrix, weights)\n",
    "RSS = np.sum((output - predictions)**2)\n",
    "RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating LASSO fit with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data_files/kc_house_train_data.csv\", dtype = dtype_dict)\n",
    "test_data = pd.read_csv(\"data_files/kc_house_test_data.csv\", dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "(multiple_feature_matrix, output) = get_numpy_data(train_data, multiple_features, 'price')\n",
    "(normalized_multiple_feature_matrix, multiple_norms) = normalize_features(multiple_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24429600.23440313        0.                0.         48389174.77154896\n",
      "        0.                0.          3317511.21492165  7329961.81171425\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.        ]\n"
     ]
    }
   ],
   "source": [
    "# l1_penalty: 1e7\n",
    "initial_weights = np.zeros(len(multiple_features) + 1)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_multiple_feature_matrix, output, initial_weights, l1_penalty, tolerance)\n",
    "print (weights1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71114625.71488702        0.                0.                0.\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.        ]\n"
     ]
    }
   ],
   "source": [
    "# l1_penalty: 1e8\n",
    "initial_weights = np.zeros(len(multiple_features) + 1)\n",
    "l1_penalty = 1e8\n",
    "tolerance = 1.0\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_multiple_feature_matrix, output, initial_weights, l1_penalty, tolerance)\n",
    "print (weights1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.87859491e+08 -1.96611439e+07  1.28893367e+07  5.20015124e+07\n",
      " -1.34448346e+06  4.40613056e+06  6.85843473e+06  4.53587116e+06\n",
      "  8.66423048e+06  1.28374342e+08  0.00000000e+00  3.64776371e+05\n",
      " -8.98872855e+08  6.49411472e+05]\n"
     ]
    }
   ],
   "source": [
    "# l1_penalty: 1e4, tolerance = 5e5\n",
    "initial_weights = np.zeros(len(multiple_features) + 1)\n",
    "l1_penalty = 1e4\n",
    "tolerance = 1\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_multiple_feature_matrix, output, initial_weights, l1_penalty, tolerance)\n",
    "print (weights1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we normalized our feature matrix, before learning the weights.  To use these weights on a test set, we must normalize the test data in the same way.\n",
    "\n",
    "**Alternatively, we can rescale the learned weights to include the normalization**, so we never have to worry about normalizing the test data: \n",
    "\n",
    "In this case, we must scale the resulting weights so that we can make predictions with *original* features:\n",
    " 1. Store the norms of the original features to a vector called `norms`:\n",
    "```\n",
    "features, norms = normalize_features(features)\n",
    "```\n",
    " 2. Run Lasso on the normalized features and obtain a `weights` vector\n",
    " 3. Compute the weights for the original features by performing element-wise division, i.e.\n",
    "```\n",
    "weights_normalized = weights / norms\n",
    "```\n",
    "Now, we can apply `weights_normalized` to the test data, without normalizing it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.31745764611762\n"
     ]
    }
   ],
   "source": [
    "normalized_weights1e4 = weights1e4 / multiple_norms\n",
    "normalized_weights1e7 = weights1e7 / multiple_norms\n",
    "normalized_weights1e8 = weights1e8 / multiple_norms\n",
    "print (normalized_weights1e7[3])\n",
    "#should return 161.31745624837794."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate each of the learned model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, multiple_features, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194415789314446.62\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix,normalized_weights1e4)\n",
    "error = prediction - test_output\n",
    "RSS = np.dot(error,error)\n",
    "print (RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275962075920366.78\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix,normalized_weights1e7)\n",
    "error = prediction - test_output\n",
    "RSS = np.dot(error,error)\n",
    "print (RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537166151497322.7\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix,normalized_weights1e8)\n",
    "error = prediction - test_output\n",
    "RSS = np.dot(error,error)\n",
    "print (RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
